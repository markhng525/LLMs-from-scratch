[project]
name = "llms-from-scratch"
version = "1.0.18"
description = "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step"
readme = "README.md"
requires-python = ">=3.11,<3.14"

dependencies = [
    "ipykernel==7.1.0",
    "tiktoken==0.12.0",
    "matplotlib==3.10.7",
    "tqdm==4.67.1",
    "numpy==2.3.5",
    "pandas==2.3.3",
    "tokenizers==0.22.1",
    "safetensors==0.7.0",
]

[project.optional-dependencies]
macos = ["torch>=2.9.0", "torchvision>=0.24.0"]

[dependency-groups]
test = ["pytest==9.0.1"]
lint = ["ruff==0.14.6", "pyrefly==0.42.0"]

[tool.pyrefly]
project_includes = ["**/*.py"]
project_excludes = [
    "**/node_modules",
    "**/.git",
    "**/.mypy_cache",
    "**/.pytest_cache",
    "**/.venv",
    "**/__pycache__",
    "**/*.pyi",
]
python_version = "3.12"

[tool.ruff]
line-length = 88

[tool.ruff.lint]
exclude = [
    ".git",
    ".mypy_cache",
    ".pytest_cache",
    ".venv",
    "__pycache__",
    "*.pyi",
]
ignore = ["C406", "E226", "E402", "E702", "E703", "E722", "E731", "E741"]
select = ["B", "C", "E", "F", "W"]
